{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(pil_img, scale):\n",
    "    w, h = pil_img.size\n",
    "    newW, newH = int(scale * w), int(scale * h)\n",
    "    assert newW > 0 and newH > 0, 'Scale is too small'\n",
    "    pil_img = pil_img.resize((newW, newH))\n",
    "\n",
    "    img_nd = np.array(pil_img)\n",
    "\n",
    "    if len(img_nd.shape) == 2:\n",
    "        img_nd = np.expand_dims(img_nd, axis=2)\n",
    "\n",
    "    # HWC to CHW\n",
    "    img_trans = img_nd.transpose((2, 0, 1))\n",
    "    if img_trans.max() > 1:\n",
    "        img_trans = img_trans / 255\n",
    "\n",
    "    return img_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = preprocess(gt, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for s, f in zip(areas, lf):\n",
    "    if s > 0:\n",
    "        f2 = f.split('.')[0] + '.jpg'\n",
    "        shutil.copy(dr + f, 'polyp_data/train2/mask/' + f)\n",
    "        shutil.copy('polyp_data/train/img/' + f2, 'polyp_data/train2/img/' + f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dr = 'polyp_data/train2/mask/'\n",
    "lf = os.listdir(dr)\n",
    "areas = []\n",
    "for i in lf:\n",
    "    with Image.open(dr + i) as im:\n",
    "        arr = np.array(im)\n",
    "        areas.append(arr[arr==255].shape[0] / arr.reshape((-1)).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011355858983583506"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(areas).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_pytorch.dice_loss import dice_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dr = 'polyp_data/test/mask/'\n",
    "lf = os.listdir(dr)\n",
    "def toarr(im):\n",
    "    im = np.array(im).astype(np.float) / 255.\n",
    "    return torch.tensor(im) \n",
    "coeff = []\n",
    "for i in lf:\n",
    "    pred = i.split('.')[0] + '_OUT.png'\n",
    "    im_pred = Image.open(dr + '../pred/' + pred)\n",
    "    im_gt = Image.open(dr + i)\n",
    "    coeff.append(dice_coeff(toarr(im_gt), toarr(im_pred)).item())\n",
    "    im_pred.close()\n",
    "    im_gt.close()\n",
    "coeff = np.array(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762475280891168"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38087520259319285"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(coeff > .9).sum() / coeff.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8646677471636953"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(coeff > .8).sum() / coeff.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983792544570502"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(coeff > .5).sum() / coeff.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88252813, 0.86617124, 0.82870382, ..., 0.97037047, 0.87393039,\n",
       "       0.77085143])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
