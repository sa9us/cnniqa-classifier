{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open('data/data.txt') as f:\n",
    "    s = f.readlines()\n",
    "cl = [i for i in s if i[-2]=='0']\n",
    "bl = [i for i in s if i[-2]=='1']\n",
    "\n",
    "l = min(len(cl), len(bl))\n",
    "r = int(l * .8)\n",
    "\n",
    "strain = random.sample(cl, r) + random.sample(bl, r)\n",
    "stest = [i for i in s if i not in strain]\n",
    "\n",
    "with open('data/train.txt', 'w') as f:\n",
    "    f.writelines(strain)\n",
    "    \n",
    "with open('data/test.txt', 'w') as f:\n",
    "    f.writelines(stest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from ignite.engine import *\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct CNN network for Image Quality Assessment (IQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNIQAnet(nn.Module):\n",
    "    def __init__(self, ker_size=7, n_kers=50, n1_nodes=800, n2_nodes=800):\n",
    "        super(CNNIQAnet, self).__init__()\n",
    "        self.conv1  = nn.Conv2d(1, n_kers, ker_size)\n",
    "        self.fc1    = nn.Linear(2 * n_kers, n1_nodes)\n",
    "        self.fc2    = nn.Linear(n1_nodes, n2_nodes)\n",
    "        self.fc3    = nn.Linear(n2_nodes, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = x.view(-1, x.size(-3), x.size(-2), x.size(-1))  #\n",
    "\n",
    "        h  = self.conv1(x)\n",
    "\n",
    "        h1 = F.max_pool2d(h, (h.size(-2), h.size(-1)))\n",
    "        h2 = -F.max_pool2d(-h, (h.size(-2), h.size(-1)))\n",
    "        h  = torch.cat((h1, h2), 1)  # max-min pooling\n",
    "        h  = h.squeeze(3).squeeze(2)\n",
    "\n",
    "        h  = F.relu(self.fc1(h))\n",
    "        h  = F.dropout(h)\n",
    "        h  = F.relu(self.fc2(h))\n",
    "\n",
    "        q  = F.softmax(self.fc3(h), dim=1)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Training Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IQADataset(Dataset):\n",
    "    def __init__(self, purpose='train'):\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        with open('data/%s.txt' % purpose) as f:\n",
    "            s = f.readlines()\n",
    "        s = [i[:-1].split() for i in s]\n",
    "        path = ['data/' + i[0] for i in s]\n",
    "        self.label = [int(i[1]) for i in s]\n",
    "        self.img = [to_tensor(Image.open(i).convert('L')) for i in path] \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], torch.tensor(self.label[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNIQAnet(\n",
      "  (conv1): Conv2d(1, 50, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=100, out_features=800, bias=True)\n",
      "  (fc2): Linear(in_features=800, out_features=800, bias=True)\n",
      "  (fc3): Linear(in_features=800, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNNIQAnet()\n",
    "device = torch.device(\"cuda\")\n",
    "    \n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "def run(epochs=200, lr=1e-4, weight_decay=0.0):\n",
    "    train_dataset = IQADataset('train')\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    global best_criterion, n_iter, a_loss\n",
    "    best_criterion = 1000\n",
    "    n_iter = 0\n",
    "    a_loss = 0\n",
    "    \n",
    "    trainer = create_supervised_trainer(model, optimizer, loss_fn, device=device)\n",
    "#     evaluator = create_supervised_evaluator(model, metrics={'accuracy': Accuracy(), 'nll': Loss(loss_fn)},\n",
    "#                                             device=device)\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED)\n",
    "    def log_training_loss(engine):\n",
    "        global n_iter, a_loss\n",
    "        a_loss += engine.state.output\n",
    "        n_iter += 1\n",
    "        if (n_iter % 20 == 0):\n",
    "            print('\\titer: %03d - avg_loss: %.5f' % (engine.state.iteration, a_loss/n_iter))\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        global best_criterion, n_iter, a_loss\n",
    "        global best_epoch\n",
    "#         evaluator.run(train_loader)\n",
    "#         metrics = evaluator.state.metrics\n",
    "#         print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "#           .format(engine.state.epoch, metrics['accuracy'], metrics['nll']))\n",
    "        loss = a_loss / n_iter\n",
    "        print('Epoch: %d - Loss: %.5f' % (engine.state.epoch, loss))\n",
    "        if loss < best_criterion:\n",
    "            best_criterion = loss\n",
    "            best_epoch = engine.state.epoch\n",
    "            torch.save(model.state_dict(), 'CNNIQA-ep=%03d-loss=%.4f' % (best_epoch, loss))\n",
    "        a_loss = 0\n",
    "        n_iter = 0\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    \n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = CNNIQAnet().cuda()\n",
    "model.load_state_dict(torch.load('CNNIQA-ep=086-loss=0.3690', map_location=device))\n",
    "\n",
    "data = IQADataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = [i[1].numpy().tolist() for i in data]\n",
    "y = []\n",
    "y_score = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(data)):\n",
    "        res = model(data[i][0].cuda())\n",
    "        v, i = res.max(1)\n",
    "        y.append(i.cpu().numpy()[0])\n",
    "        y_score.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuray (using 0.5 as threshold for this binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260869565217391"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516561331524437"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y, [i[0][1].cpu().numpy().tolist() for i in y_score])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
